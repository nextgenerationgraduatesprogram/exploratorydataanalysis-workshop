{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "# import ucimlrepo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Access Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Dataset\n",
    "We will access the dataset via. the URL. However, UCI does provide a Python library which you can use if desired: https://archive.ics.uci.edu/dataset/10/automobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data to \"automobile.zip\"\n",
    "import urllib\n",
    "_, response = urllib.request.urlretrieve(\"https://archive.ics.uci.edu/static/public/10/automobile.zip\", \"automobile.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the data\n",
    "from zipfile import ZipFile\n",
    "with ZipFile(\"automobile.zip\", \"r\") as zObj:\n",
    "    zObj.extractall(path=\"automobile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the downloaded items\n",
    "from pathlib import Path\n",
    "print(\"[ Downloaded Files ]\")\n",
    "for idx, p in enumerate(Path(\"automobile\").glob(\"*\")):\n",
    "    print(f\"{idx}: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the local data\n",
    "fp = \"automobile/imports-85.data\"\n",
    "\n",
    "# Data headers\n",
    "header = [\n",
    "    'symboling', \n",
    "    'normalized-losses', \n",
    "    'make', \n",
    "    'fuel-type', \n",
    "    'aspiration', \n",
    "    'num-of-doors', \n",
    "    'body-style', \n",
    "    'drive-wheels', \n",
    "    'engine-location', \n",
    "    'wheel-base', \n",
    "    'length', \n",
    "    'width', \n",
    "    'height', \n",
    "    'curb-weight', \n",
    "    'engine-type', \n",
    "    'num-of-cylinders', \n",
    "    'engine-size', \n",
    "    'fuel-system', \n",
    "    'bore', \n",
    "    'stroke', \n",
    "    'compression-ratio', \n",
    "    'horsepower', \n",
    "    'peak-rpm', \n",
    "    'city-mpg', \n",
    "    'highway-mpg', \n",
    "    'price'\n",
    "] \n",
    "\n",
    "# Read the CSV file from the URL and assign column names \n",
    "df = pd.read_csv(fp, names=header, na_values='?')\n",
    "\n",
    "# Display the first few rows of the DataFrame \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access data directly via. URL\n",
    "\n",
    "You can optionally access the data directly via. the provided URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data' \n",
    "\n",
    "# # Read the CSV file from the URL and assign column names \n",
    "# df = pd.read_csv(url, names=header, na_values='?')\n",
    "\n",
    "# # Display the first few rows of the DataFrame \n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Breakout Session 1\n",
    "Univariate Analysis to understand the distributions and central tendencies of individual features.\n",
    "\n",
    "### Objective:​\n",
    "\n",
    "To delve into the characteristics and distributions of individual features within the dataset.​\n",
    "\n",
    "### Agenda:​\n",
    "\n",
    "Data Preprocessing: pre-process the dataset to ensure quality and consistency by handling missing values.​\n",
    "\n",
    "Visualise Feature Distributions: Utilise histograms, box plots, and other suitable plots to visualise feature distributions and discuss their central tendencies (mean, median, mode).​\n",
    "\n",
    "Descriptive Statistics: Generate summary statistics to provide insights into the numerical attributes of the dataset by highlighting key metrics such as mean, standard deviation, and quartiles.​\n",
    "\n",
    "Key Insights and Preliminary Findings: Identify patterns, trends, and outliers within individual features and formulating preliminary findings.\n",
    "\n",
    "### Deliverables:\n",
    "\n",
    "Cleaned and pre-processed dataset ready for analysis.​\n",
    "\n",
    "Descriptive statistics summary highlighting key numerical attributes.​\n",
    "\n",
    "Visualizations showcasing feature distributions and central tendencies.​\n",
    "\n",
    "Preliminary findings document outlining initial observations and potential areas for exploration.​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the dataset to handle missing values and ensure consistency (see additional instructions at the end of this task). \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Familiarise yourself with the different features available in the dataset. \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore individual features to understand their distributions and central tendencies. \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the distributions using histograms, box plots, or other suitable plots.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Breakout Session 2\n",
    "Bivariate Analysis to investigate relationships between pairs of features and their impact on car prices.​\n",
    "\n",
    "### Objective: ​\n",
    "\n",
    "To investigate the relationships between different features and their impact on car prices​\n",
    "\n",
    "### Agenda:​\n",
    "\n",
    "Data Exploration Techniques: Review scatter plots to visualise relationships between pairs of features. Utilise box plots to identify variations in car prices across different feature categories.​\n",
    "\n",
    "Correlation Analysis: Conduct correlation analysis to quantify the strength and direction of relationships between numerical features and car prices. Discuss the significance of correlation coefficients in understanding feature impacts.​\n",
    "\n",
    "Findings on Feature Impact on Car Prices: Analyse scatter plots and box plots to discern patterns and trends in feature-price relationships. Discuss the impact of specific feature pairs on car prices, including both positive and negative correlations.​\n",
    "\n",
    "Insights and Recommendations: Derive insights into the most influential features affecting car prices. Formulate recommendations for feature highlighting and pricing strategies based on the findings.\n",
    "\n",
    "### Deliverables:\n",
    "\n",
    "Scatter plots and box plots illustrating feature relationships with car prices.​\n",
    "\n",
    "Correlation matrix highlighting the strength of associations between features.​\n",
    "\n",
    "Discussion of findings regarding the impact of feature pairs on car prices.​\n",
    "\n",
    "Recommendations for feature highlighting and pricing strategies based on the analysis.​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate relationships between pairs of features and their impact on car prices. \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scatter plots, box plots, or correlation analysis to explore these relationships. \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Breakout Session 3\n",
    "Customised Plotting to create visualisations tailored to the dataset for enhanced interpretability.\n",
    "\n",
    "### Objective: \n",
    "\n",
    "To create tailored visualisations that effectively communicate insights from the dataset and enhance interpretability.​\n",
    "\n",
    "### Agenda:​\n",
    "\n",
    "Selecting Plot Types and Customisation Techniques: Review various plot types (e.g., bar charts, line plots, heatmaps) suitable for different data types and relationships. Demonstrate customisation techniques to enhance aesthetics and clarity of visualizations.​\n",
    "\n",
    "Interpreting Visualizations: Discuss key insights derived from the visualisations. Analysing patterns, trends, and outliers revealed by the customized visualizations.​\n",
    "\n",
    "### Deliverables:\n",
    "\n",
    "Customised visualizations tailored to the dataset, including bar charts, line plots, scatter plots, and heatmaps.​\n",
    "\n",
    "Aesthetic enhancements such as color coding, labeling, and annotations for clarity.​\n",
    "\n",
    "Interpretation of insights gleaned from the visualizations, with a focus on actionable takeaways.​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create customised visualizations tailored to the dataset to enhance interpretability. \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select appropriate plot types and customise their aesthetics for clarity. \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Breakout Session 4\n",
    "Dimensionality Reduction & Key Findings to apply PCA for dimensionality reduction and summarise key insights.​\n",
    "\n",
    "### Objective: \n",
    "\n",
    "To identify key factors driving price variance using Principal Component Analysis (PCA).​\n",
    "\n",
    "### Agenda:​\n",
    "\n",
    "PCA Implementation and Interpretation: Apply PCA on the dataset to identify principal components. Interpret of PCA results, including variance explained by each component and loadings of original features.​\n",
    "\n",
    "Key Insights from PCA Analysis: Discuss key insights derived from PCA, including dominant factors influencing price variance. Identify of significant features contributing to each principal component.​\n",
    "\n",
    "Recommendations for Pricing Strategies: Formulate segmented pricing strategies based on identified factors influencing price variance. Discuss pricing adjustments and promotions tailored to different customer segments.​\n",
    "\n",
    "### Deliverables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Principal Component Analysis (PCA) to reduce the dimensionality of the dataset. \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify key factors influencing price variance using PCA. \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
